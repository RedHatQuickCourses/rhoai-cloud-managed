= Red Hat AI on AWS Cloud
:navtitle: Home

=== Example Use-case

A Red Hat customer reaches out because they are beginning a new generative AI project and want to know if you have any reference use cases or frameworks for organizations being their AI powered application journey. 

They are already an AWS customer but are looking for an alternative way to deploy AI models without needing data scientists or MLOps engineers, instead a team of developers and IT operations will be leading this project.   The team needs a new chatbot service for their call center that can provide an internal only portal for associates to utilize.

The solution needs to scale to provide similar service across the organization, in phase two, become a chat resource to external customers, and in phase 3 it should learn from chats and request new information automatically. 


== Introduction

This course is intended for Red Hat Technical Sales, Solution Architects, Support and Services team members who are discussing Red Hat AI platform solutions with customers who utilize AWS cloud services or have the flexibility to use AWS cloud services to provision such environments.

Waiting for hardware can take weeks or months, which is why obtaining an Red Hat AI Platforms from Cloud providers, AWS specifically in this course, in minutes can be a crucial component for unlocking the full potential of *Generative AI* and *Predictive AI* for organizations on the move.

Utilizing on-demand cloud resources to evaluate, experiment and fine tune open-source  AI models can allow organizations to avoid purchasing high-cost GPUs used for model training and inferencing, instead using only what is needed and shutting down research and development projects when complete.

This course will focus only on Red Hat AI solutions that can be instantiated on the AWS Cloud Provider while reviewing the AWS AI Services that can be used in combination with Red Hat Services to provide an approach that avoids vendor lock in.

For those not familiar with the Red Hat AI Platform, it  is made up of Red Hat Enterprise Linux AI ( RHEL AI ) and Red Hat OpenShift AI ( RHOAI ).

RHEL AI is targeted towards customers who are looking for a Generative AI fine tuning and model inferencing platform that can be run across cloud hyperscalers and on premises providing a hybrid cloud experience utilizing a single platform for engineers and operations.

RHOAI - is a fully scalable Machine Learning Operations Platform( MLOps ) platform that provides the ability to automate data collection, processing and preparation. Then automate model experimentation, training, and versioning using pipelines. Finally serving models securely, with OpenShift providing the infrastructure to run AI powered applications.


== Objectives

==== On completing this course, you should be able to:

  * Describe how AWS Cloud Deployment can simplify Red Hat AI Adoption
  * Understand how to Deploy Red Hat AI Solutions on AWS
  * Identify the difference between Red Hat AI Platform and AWS SaaS offerings
  * Explain the value / benefits of RHOAI cloud services
  * Identify Red Hatâ€™s AI platforms that comprise Red Hat AI that can run on AWS
  * Explain how to deploy RHEL AI on AWS. 
  * Explain the customer challenges that RHOAI Cloud Service can address.
  * Hands on Activities - Getting hands on with AWS AI Services
  * Hands on Activities - External Lab- Deploy Red Hat AI on AWS
  * Hands on Activities - Rosa Hands on Lab

=== 

Contributors
The PTL team acknowledges the valuable contributions of the following Red Hat associates:

Karlos Knox

== Classroom Environment

Launch an https://demo.redhat.com/catalog?search=AWS+Blank+Open+Environment&item=babylon-catalog-prod%2Fsandboxes-gpte.sandbox-open.prod[AWS Blank Open Environment, window=blank] to follow along with this guided lab.


