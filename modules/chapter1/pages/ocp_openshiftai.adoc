= Red Hat AI Deployment Options on AWS

== Objectives

 * Identify Red Hat’s AI platforms that comprise Red Hat AI.
 * Describe how AWS Cloud Deployment can simplify Red Hat AI Adoption
 * Understand how to Deploy Red Hat AI Solutions on AWS
 * Explain the customer challenges that RHOAI Cloud Service can address.

== Red Hat AI Platform

The Red Hat AI platform includes RHEL AI and OpenShift AI which will be delivered as an integrated solution

While RHEL AI can be purchased and installed without any additional subscriptions, RHOAI is an add-on feature set which requires OpenShift Container Platform cluster subscription. 

===  RHEL AI
RHEL AI is specially designed for open-source Generative AI model fine tuning and inference.

 . Provides a simplified approach to get started with generative AI that includes open source models
 . Makes AI accessible to developers and domain experts with little data science expertise
 . Provides the ability to do training &  inference on individual production server deployments

=== OpenShift AI

OpenShift AI is a fully functional MLOPs platform which is capable of providing life cycle management for both predictive and generative AI solutions.

 . Provides support for both generative and predictive AI models with a BYOM approach
 . Includes distributed compute, collaborative workflows, model serving and monitoring
 . Offers enterprise MLOps capabilities and the ability to scale across hybrid-clouds
 . Includes Red Hat Enterprise Linux AI, including the Granite family models


Depending on an organization's maturity in AI model powered application development, both solutions provide entry points into AI solutions with RHEL AI focusing on those earlier in the journey, and OpenShift AI focused on solving the entire lifecycle of enterprise multi-AI model application development all way though model model montioring and maintenance in production.

While this course focuses on AWS deployments, either of these solutions can be deployed across multiple cloud provider and on-premises environments including _disconnected or air-gapped environment which going forward will be known as  *Private AI*._

== FictionCorp 

As stated in the introduction, our FictionCorp organization wants to create a AI powered chat application for their call center.  There existing knowledge base is currently stored in AWS but requires each representative to search through documentation which adds time to each call or chat.  Based on the associates tenture these search can take from 5-20 minutes. 

The goal is reduce documentation search to 2 minutes so that it can be utilized on the initial call and reduce response times to customers request.

Before we start solutioning their needs, let's review the benefits of using Red Hat managed service offering of OpenShift AI as a possible solution.

We should always start with OpenShift AI as it offers the most feature rich platform for entire AI model lifecycle management, and offers a centrailized dashboard for cross-functional team to collaborate.


== OpenShift AI on AWS as a managed offering

A managed service shifts the burden of managing the infrastructure and platform software to your service, allowing teams to focus on building and supporting the applications that move the needle for the business rather than support the infrastructure.

Think of this as spending time to build the factory or using the factory to produce the goods and services to be sold.  Which provides more value to the business?

Easy to configure via DevOps CI/CD practices and allows teams to self-service RHOAI resources via the included user dashboard. 

==  OpenShift AI Cloud Service Dependencies

Red Hat OpenShift AI is available as a fully Red Hat and AWS co-managed cloud service that is available as an add-on to:

 * Red Hat OpenShift Dedicated on AWS
 * Red Hat OpenShift Service on AWS (ROSA Classic)

[IMPORTANT]
Both OpenShift and OpenShift AI add-on subscriptions are required.


=== Estimated pricing may vary per region and machine type.

OpenShift AI Add-on .022 per hour per 4vCPUs allocated.
+
OpenShift Container Cluster Platform ; $0.33/hr
OpenShift Container Cluster Platform Plus;  $0.41/hr

----
Remove this section and below
----


=== OpenShift AI Add-on Requirements

Installing OpenShift AI as a managed cloud service add-on involves the following high-level tasks:

 * Confirm that your OpenShift cluster meets all requirements.
 * Configure an identity provider for your OpenShift cluster.
 * Add administrative users for your OpenShift cluster.
 * Subscribe to the Red Hat OpenShift AI Add-on.

For OpenShift Dedicated with a CCS for AWS get a subscription through Red Hat.

[NOTE]
Customer Cloud Subscriptions (CCS) on AWS such as OpenShift Dedicated utilizes a Customer Cloud Subscription (CCS) model that allows Red Hat to deploy and manage clusters into a customer’s existing Amazon Web Service (AWS) account.

An OpenShift Dedicated or ROSA cluster configuration that meets the following requirements:
At least 2 worker nodes with at least 8 CPUs and 32 GiB RAM available for OpenShift AI to use when you install the Add-on. If this requirement is not met, the installation process fails to start and an error is displayed.

When you create a new cluster, select m6a.2xlarge for the computer node instance type to satisfy the requirements.


'''


[NOTE]
You can also purchase Red Hat OpenShift AI as self-managed software. To purchase a new subscription, contact your Red Hat account manager. If you do not yet have an account manager, complete the form at https://www.redhat.com/en/contact to request one.

